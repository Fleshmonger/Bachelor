\chapter{Project Process}
\label{ch:process}
The project was developed with the agile development process, but no particular agile method was used. Design and implementation were iterated upon across short, week-long sprints. After each there was an evaluation of the agent's current status and new goals would be identified for the next sprint. The project plan took form as a backlog, kept during development, and was used when determining the status and goals in scope of the whole time-plan. There were a few milestones throughout development, usually a month apart. They set requirements towards what the agent should satisfy at specific points in the development. The milestones served as a medium between sprints and the overall goal, ensuring both that the bot improved consistently, and that a satisfactory end-result would be met.

Testing was done in two steps. First the robustness of the implementations was tested by playing the bot against the official built-in StarCraft bots. This was done across all the maps used in the competitions. This was to ensure the stability of the bot and that the implementations worked as required, across all the maps it would play on. The second step was uploading the bot to the \emph{Student StarCraft AI Tournament} (SSCAIT) website, where the bot would play against other bots. This would serve to test the gameplay performance of the bot, and was done less often than the first step in order to retrieve enough statistical data. This was much slower than testing locally, as the matches were played in real-time, but necessary to ensure the opponents were up-to-date. The bots on the SSCAIT website should be updated at least since the last tournament (January, 2015), so that they are the best candidates to test the agent's abilities. Because it is time-consuming to retrieve data from matches on the SSCAIT, the first step was needed to determine crash issues and such technicalities, in order to not waste time.

\section{Project Plan}
The project started in late-January and development ended early June, with four milestones in between. We will briefly explain them:

The first milestone was attaining the minimum viable product by the end of February. The requirements for this was an agent capable of defeating a passive opponent, implying means to gather resources, build units, scouting and attacking. This would imply the agent had a non-zero chance at winning a match.

The second milestone was generalizing and polishing the first solutions at the end of March, executing the agent's strategy more efficiently. This included efficient production and resource gathering, simple combat prediction and an information manager of enemy units.

By late April, the third milestone required more strategic elements such as base-defense, better unit grouping with retreating and expansions.

The final milestone by late May to mid-Jun required the use of advanced units and technology upgrades, with possible features such as improved expansion, scout harassment or enemy economy disruption. It was somewhat open-ended, as it was unknown which features would be most needed at the time.

The first two milestones were completed with all required features. By the third milestone however, the expansion feature proved much more time-consuming to implement than predicted. Meanwhile, preliminary results with advanced units suggested a lot of work was required to make them more efficient than just using basic units. For those reasons, advanced units as a feature was scrapped in favor of completing the expansion feature. As with advanced units, expansions were only worthwhile if they were efficient, which required a generalized implementation, better expansion locations and the Maynard slide technique. As a result, the last milestone goals were not satisfied, as improved expansion had been implemented, but the rest was not. On the other hand, in the final version of the agent, all the features had been implemented with good gameplay performance, few and minor bugs and with no reported crashes.

The final features took longer than predicted, since they had to be at least as efficient as the rest of the agent's features to be worthwhile. It was easy to implement a simple version of the features, but gameplay performance demanded the consideration of many edge-cases to be efficient. Implementing a single feature well would have a better chance of increasing the agent's win-rate.